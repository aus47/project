{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoHp8wn5jG9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bd31484a-9236-45fb-c3ae-43b6872de500"
      },
      "source": [
        "import re                                       # regular expressions\n",
        "from sklearn.svm import LinearSVC\n",
        "from nltk.classify import SklearnClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# To do preprocessing\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# To do preprocessing\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('words')\n",
        "\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
        "import numpy as np # To compute the average results\n",
        "\n",
        "from random import shuffle # To shuffle the dataset\n",
        "\n",
        "\n",
        "# To use feature selection in the Pipeline\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import gensim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhcSeC_CfSC8",
        "colab_type": "text"
      },
      "source": [
        "Load data file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64HVrcHlgRA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = 'topic_with_sentiment.csv'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI24G83fjsCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(filepath, sep=\",\", error_bad_lines=False, encoding='latin-1')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX4NaqSzgEPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5ee20c95-7e54-4e92-8f86-7b65ca918181"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Topic_assigned</th>\n",
              "      <th>Topic_Percentage</th>\n",
              "      <th>Ground_Truth</th>\n",
              "      <th>Ground_Truth_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pleasure ing 7 night recently perfect every wa...</td>\n",
              "      <td>Service</td>\n",
              "      <td>0.2340</td>\n",
              "      <td>Facilities  Comfort Food  Staff Location Service</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lovely first visit iconic bar wonderful servic...</td>\n",
              "      <td>Service</td>\n",
              "      <td>0.2886</td>\n",
              "      <td>Food Price   Service</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3 u ed rhodes_hotel 4 night location take padd...</td>\n",
              "      <td>Price</td>\n",
              "      <td>0.1645</td>\n",
              "      <td>Facilities Cleanliness    Staff Location</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>form moment_arrive left experienced absolute_p...</td>\n",
              "      <td>Service</td>\n",
              "      <td>0.2637</td>\n",
              "      <td>Food  Staff  Service</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>well strange 5star new come along eager try he...</td>\n",
              "      <td>Staff</td>\n",
              "      <td>0.2831</td>\n",
              "      <td>Facilities Cleanliness  Food Price Staff  Service</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ... Ground_Truth_Sentiment\n",
              "0  pleasure ing 7 night recently perfect every wa...  ...                      5\n",
              "1  lovely first visit iconic bar wonderful servic...  ...                      5\n",
              "2  3 u ed rhodes_hotel 4 night location take padd...  ...                      4\n",
              "3  form moment_arrive left experienced absolute_p...  ...                      5\n",
              "4  well strange 5star new come along eager try he...  ...                      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci9uYrFegZUX",
        "colab_type": "text"
      },
      "source": [
        "Cleaning data (remove minor reviews, replace 5 labels with 3 labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPWzgCGfkYPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[data.Ground_Truth_Sentiment != 0]\n",
        "data = data[data.Ground_Truth_Sentiment != 6]\n",
        "data = data[data.Ground_Truth_Sentiment != 7]\n",
        "data = data[data.Ground_Truth_Sentiment != 8]\n",
        "data = data[data.Ground_Truth_Sentiment != 9]\n",
        "data = data[data.Ground_Truth_Sentiment != 10]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWe7VeXtkiOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['Ground_Truth_Sentiment'] = data['Ground_Truth_Sentiment'].replace(1, 0)\n",
        "data['Ground_Truth_Sentiment'] = data['Ground_Truth_Sentiment'].replace(2, 0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c-IQQR0BKWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['Ground_Truth_Sentiment'] = data['Ground_Truth_Sentiment'].replace(3, 1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3z87mpAkn95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['Ground_Truth_Sentiment'] = data['Ground_Truth_Sentiment'].replace(4, 2)\n",
        "data['Ground_Truth_Sentiment'] = data['Ground_Truth_Sentiment'].replace(5, 2)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKVW9ozwFQQh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4eafb4ab-50d1-4c70-e45c-834a183eb2ea"
      },
      "source": [
        "data['Ground_Truth_Sentiment'].value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    381598\n",
              "1     98710\n",
              "0     39253\n",
              "Name: Ground_Truth_Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzd-DAhNksuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preProcess(text):\n",
        "    # should return a list of tokens\n",
        "    \n",
        "    # word tokenisation, including punctuation removal\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(str(text))\n",
        "    \n",
        "    # lowercasing\n",
        "    tokens = [t.lower() for t in tokens]\n",
        "\n",
        "    # stopword removal- benefits are it removes rare words, though bad for bigram relations\n",
        "    stop = set(stopwords.words('english'))\n",
        "    tokens = [t for t in tokens if t not in stop]\n",
        "    \n",
        "    # lemmatisation\n",
        "    lemmatiser = WordNetLemmatizer()\n",
        "    tokens = [lemmatiser.lemmatize(t) for t in tokens]\n",
        "    tokens = [t for t in tokens if t] # ensure no empty space\n",
        "\n",
        "    # remove numbers\n",
        "    digits = '0123456789'\n",
        "    tokens = [t for t in tokens if t not in digits]\n",
        "\n",
        "    #bigram_mod = create_bigrams(tokens)\n",
        "    #tokens = [bigram_mod[line] for line in tokens]\n",
        "    \n",
        "    return tokens"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGEi1enW5tGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if use 2 feature only (text with labels)\n",
        "#def toFeatureVector(words):\n",
        "    # return a dictionary 'featureVect' where the keys are the tokens in 'words' and the values are the number of occurrences of the tokens\n",
        "    # start by using binary values only:\n",
        "#    counts = Counter(words)\n",
        "#    return {w: counts[w]/sum(counts.values()) for w in counts.keys()}#{w: 1.0/len(words) for w in words}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvDdP-OdlLMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use 3 features (text with labels and pro. of topics)\n",
        "featureDict = {} # the global feature dictionary\n",
        "\n",
        "def toFeatureVector(tokens, topics):\n",
        "    # return a dictionary 'featureVect' where the keys are the tokens in 'words' and the values are the number of occurrences of the tokens\n",
        "    # start by using binary values only:\n",
        "#     baseDict = {}\n",
        "    featureVec = {}\n",
        "\n",
        "    for w in tokens:\n",
        "        try:\n",
        "            featureVec[w] += 1.0/len(tokens)\n",
        "        except KeyError:\n",
        "            featureVec[w] = 1.0/len(tokens)\n",
        "        try:\n",
        "            featureDict[w] += 1.0/len(tokens)\n",
        "        except KeyError:\n",
        "            featureDict[w] = 1.0/len(tokens)\n",
        "    \n",
        "    # just get bigram binary presence or not\n",
        "    for i in range(1, len(tokens)):\n",
        "        bigram = tokens[i-1] + \" \" + tokens[i]\n",
        "        try:\n",
        "            featureVec[bigram] = 1 #+= 1.0/len(tokens)\n",
        "        except KeyError:\n",
        "            featureVec[bigram] = 1 #= 1.0/len(tokens)\n",
        "        try:\n",
        "            featureDict[bigram] += 1.0\n",
        "        except KeyError:\n",
        "            featureDict[bigram] = 1.0\n",
        "\n",
        "    featureVec['Topics:'+str(topics)] = 1.0 #0.3\n",
        "        \n",
        "    try:\n",
        "        featureVec['topics:'+topics] += 1.0\n",
        "    except KeyError:\n",
        "         featureDict['topics:'+topics] = 1.0\n",
        "    \n",
        "    return featureVec"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viv4d3R3mf35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def splitData(percentage):\n",
        "    dataSamples = len(rawData)\n",
        "    halfOfData = int(len(rawData)/2)\n",
        "    trainingSamples = int((percentage*dataSamples)/2)\n",
        "    for (Text,label,t) in rawData[:trainingSamples] + rawData[halfOfData:halfOfData+trainingSamples]:\n",
        "        trainData.append((toFeatureVector(preProcess(Text), t),label))\n",
        "    for (Text,label,t) in rawData[trainingSamples:halfOfData] + rawData[halfOfData+trainingSamples:]:\n",
        "        testData.append((toFeatureVector(preProcess(Text), t),label))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r3HPNvbAucT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if use 2 features only\n",
        "#def splitData(percentage):\n",
        "#    dataSamples = len(rawData)\n",
        "#    halfOfData = int(len(rawData)/2)\n",
        "#    trainingSamples = int((percentage*dataSamples)/2)\n",
        "#    for (Text,label) in rawData[:trainingSamples] + rawData[halfOfData:halfOfData+trainingSamples]:\n",
        "#        trainData.append((toFeatureVector(preProcess(Text)),label))\n",
        "#    for (Text,label) in rawData[trainingSamples:halfOfData] + rawData[halfOfData+trainingSamples:]:\n",
        "#        testData.append((toFeatureVector(preProcess(Text)),label))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb0hBhsXmuxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
        "\n",
        "def trainClassifier(trainData, classifier_name):\n",
        "    print(\"Training Classifier...\")\n",
        "    pipeline =  Pipeline([('tfidf', TfidfTransformer()),('chi2', SelectKBest(chi2, k=20000)),('cl', classifier_name)])\n",
        "    #pipeline = Pipeline([('tfidf', TfidfTransformer()), ('sampling', SMOTE()),('classification', classifier_name)])\n",
        "    return SklearnClassifier(pipeline).train(trainData)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsYcZFPAkszU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
        "\n",
        "def predictLabels(reviewSamples, classifier):\n",
        "    return classifier.classify_many(map(lambda t: t[0], reviewSamples))\n",
        "\n",
        "def predictLabel(text, classifier):\n",
        "    return classifier.classify(toFeatureVector(preProcess(text)))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyCTEI7cm08w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crossValidate(dataset, folds, classifier_name):\n",
        "    shuffle(dataset)\n",
        "    results = []\n",
        "    foldSize = int(len(dataset)/folds)\n",
        "\n",
        "    \n",
        "    for i in range(0,len(dataset),foldSize):\n",
        "        # insert code here that trains and tests on the 10 folds of data in the dataset\n",
        "        print(\"Fold start on items %d - %d\" % (i, i+foldSize))\n",
        "        myTestData = dataset[i:i+foldSize]\n",
        "        myTrainData = dataset[:i] + dataset[i+foldSize:]\n",
        "        classifier = trainClassifier(myTrainData, classifier_name)\n",
        "        y_true = list(map(lambda x: x[1], myTestData))\n",
        "        y_pred = predictLabels(myTestData, classifier)\n",
        "        results.append(precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0))\n",
        "        \n",
        "    avgResults = list(map(np.mean,list(zip(*results))[:3]))\n",
        "    return avgResults"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA-WQGaom1BT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyM80Gmpg_jC",
        "colab_type": "text"
      },
      "source": [
        "Choose subgroup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyWBydVthHoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic = ['Staff, Location', \n",
        "         'Location', \n",
        "         'Comfort, Clealiness', \n",
        "         'Facilities', \n",
        "         'Location, Food', \n",
        "         'Food',\n",
        "         'Staff', \n",
        "         'Service', \n",
        "         'Price']"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xMyDoq9hL_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subgroup = data[data.Topic_assigned == topic[0]]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av9OBvSuV3GZ",
        "colab_type": "text"
      },
      "source": [
        "Prepare Data to train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU32GeyV8TTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subgroup['Ground_Truth_Sentiment'] = subgroup['Ground_Truth_Sentiment'].apply(str)\n",
        "subgroup['Topic_Percentage'] = subgroup['Topic_Percentage'].apply(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyy7-3UHzZWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = subgroup['Text'].values.tolist()\n",
        "topics = subgroup['Topic_Percentage'].values.tolist()\n",
        "label = subgroup['Ground_Truth_Sentiment'].values.tolist()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_OnEZKx2zJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rawData = []\n",
        "\n",
        "#if use 2 features\n",
        "#for sent, l in zip(x, label):   \n",
        "#    rawData.append((sent, l))\n",
        "\n",
        "for sent, l, t in zip(x, label, topics):   \n",
        "    rawData.append((sent, l, t))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5LG8o8NlrFa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "20cc3bf8-a42f-4d17-d0df-32a0e1719ad6"
      },
      "source": [
        "trainData = [] # the training data as a percentage of the total dataset\n",
        "testData = [] # the test data as a percentage of the total dataset\n",
        "# references to the data files\n",
        "\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)))\n",
        "print(\"Preparing the dataset...\")\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)))\n",
        "print(\"Preparing training and test data...\")\n",
        "splitData(0.8)\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now 80021 rawData, 0 trainData, 0 testData\n",
            "Preparing the dataset...\n",
            "Now 80021 rawData, 0 trainData, 0 testData\n",
            "Preparing training and test data...\n",
            "Now 80021 rawData, 64016 trainData, 16005 testData\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycH7lsRRKs8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#svc = LinearSVC(max_iter=10000)\n",
        "svm = SVC(class_weight='balanced')\n",
        "dt = DecisionTreeClassifier(class_weight='balanced')\n",
        "rf = RandomForestClassifier(class_weight='balanced')\n",
        "nb = MultinomialNB()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ6GEWMLA-Q8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1744d002-b3d0-4111-e5cd-c245b8f9b368"
      },
      "source": [
        "svm_c = crossValidate(trainData, 10, svm)\n",
        "print('Finished training SVC classifier!')\n",
        "\n",
        "dt_c = crossValidate(trainData, 10, dt)\n",
        "print('Finished training Decision Tree classifier!')\n",
        "\n",
        "rf_c = crossValidate(trainData, 10, rf)\n",
        "print('Finished training Random Forest classifier!')\n",
        "\n",
        "nb_c = crossValidate(trainData, 10, nb)\n",
        "print('Finished training Naive Bayes classifier!')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold start on items 0 - 6401\n",
            "Training Classifier...\n",
            "Fold start on items 6401 - 12802\n",
            "Training Classifier...\n",
            "Fold start on items 12802 - 19203\n",
            "Training Classifier...\n",
            "Fold start on items 19203 - 25604\n",
            "Training Classifier...\n",
            "Fold start on items 25604 - 32005\n",
            "Training Classifier...\n",
            "Fold start on items 32005 - 38406\n",
            "Training Classifier...\n",
            "Fold start on items 38406 - 44807\n",
            "Training Classifier...\n",
            "Fold start on items 44807 - 51208\n",
            "Training Classifier...\n",
            "Fold start on items 51208 - 57609\n",
            "Training Classifier...\n",
            "Fold start on items 57609 - 64010\n",
            "Training Classifier...\n",
            "Fold start on items 64010 - 70411\n",
            "Training Classifier...\n",
            "Finished training SVC classifier!\n",
            "Fold start on items 0 - 6401\n",
            "Training Classifier...\n",
            "Fold start on items 6401 - 12802\n",
            "Training Classifier...\n",
            "Fold start on items 12802 - 19203\n",
            "Training Classifier...\n",
            "Fold start on items 19203 - 25604\n",
            "Training Classifier...\n",
            "Fold start on items 25604 - 32005\n",
            "Training Classifier...\n",
            "Fold start on items 32005 - 38406\n",
            "Training Classifier...\n",
            "Fold start on items 38406 - 44807\n",
            "Training Classifier...\n",
            "Fold start on items 44807 - 51208\n",
            "Training Classifier...\n",
            "Fold start on items 51208 - 57609\n",
            "Training Classifier...\n",
            "Fold start on items 57609 - 64010\n",
            "Training Classifier...\n",
            "Fold start on items 64010 - 70411\n",
            "Training Classifier...\n",
            "Finished training Decision Tree classifier!\n",
            "Fold start on items 0 - 6401\n",
            "Training Classifier...\n",
            "Fold start on items 6401 - 12802\n",
            "Training Classifier...\n",
            "Fold start on items 12802 - 19203\n",
            "Training Classifier...\n",
            "Fold start on items 19203 - 25604\n",
            "Training Classifier...\n",
            "Fold start on items 25604 - 32005\n",
            "Training Classifier...\n",
            "Fold start on items 32005 - 38406\n",
            "Training Classifier...\n",
            "Fold start on items 38406 - 44807\n",
            "Training Classifier...\n",
            "Fold start on items 44807 - 51208\n",
            "Training Classifier...\n",
            "Fold start on items 51208 - 57609\n",
            "Training Classifier...\n",
            "Fold start on items 57609 - 64010\n",
            "Training Classifier...\n",
            "Fold start on items 64010 - 70411\n",
            "Training Classifier...\n",
            "Finished training Random Forest classifier!\n",
            "Fold start on items 0 - 6401\n",
            "Training Classifier...\n",
            "Fold start on items 6401 - 12802\n",
            "Training Classifier...\n",
            "Fold start on items 12802 - 19203\n",
            "Training Classifier...\n",
            "Fold start on items 19203 - 25604\n",
            "Training Classifier...\n",
            "Fold start on items 25604 - 32005\n",
            "Training Classifier...\n",
            "Fold start on items 32005 - 38406\n",
            "Training Classifier...\n",
            "Fold start on items 38406 - 44807\n",
            "Training Classifier...\n",
            "Fold start on items 44807 - 51208\n",
            "Training Classifier...\n",
            "Fold start on items 51208 - 57609\n",
            "Training Classifier...\n",
            "Fold start on items 57609 - 64010\n",
            "Training Classifier...\n",
            "Fold start on items 64010 - 70411\n",
            "Training Classifier...\n",
            "Finished training Naive Bayes classifier!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA5aUfadN1gF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_result_table(classifier1, classifier2, classifier3, classifier4):\n",
        "    model_scores = pd.DataFrame({'Support Vector Machine':[classifier1[0], classifier1[1], classifier1[2]],\n",
        "                                       \n",
        "                                 'Decision Tree':[classifier2[0], classifier2[1], classifier2[2]],\n",
        "                                       \n",
        "                                 'Random Forest':[classifier3[0], classifier3[1], classifier3[2]],\n",
        "                                       \n",
        "                                 'Naive Bayes':[classifier4[0], classifier4[1], classifier4[2]]},\n",
        "                                      \n",
        "                                  index=['Precision', 'Recall', 'F1 Score'])\n",
        "    \n",
        "    # Add 'Best Score' column\n",
        "    model_scores['Best Score'] = model_scores.idxmax(axis=1)\n",
        "\n",
        "    return model_scores"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2rEIkl_TCJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_scores = create_result_table(svm_c, dt_c, rf_c, nb_c)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1XZ1PZLWSkJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "69b9d57a-9049-4317-c331-da8ede5099a8"
      },
      "source": [
        "model_scores.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Support Vector Machine</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>Naive Bayes</th>\n",
              "      <th>Best Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Precision</th>\n",
              "      <td>0.803571</td>\n",
              "      <td>0.823984</td>\n",
              "      <td>0.812713</td>\n",
              "      <td>0.766177</td>\n",
              "      <td>Decision Tree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall</th>\n",
              "      <td>0.791825</td>\n",
              "      <td>0.802644</td>\n",
              "      <td>0.862905</td>\n",
              "      <td>0.875207</td>\n",
              "      <td>Naive Bayes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1 Score</th>\n",
              "      <td>0.795794</td>\n",
              "      <td>0.812828</td>\n",
              "      <td>0.834400</td>\n",
              "      <td>0.817021</td>\n",
              "      <td>Random Forest</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Support Vector Machine  Decision Tree  ...  Naive Bayes     Best Score\n",
              "Precision                0.803571       0.823984  ...     0.766177  Decision Tree\n",
              "Recall                   0.791825       0.802644  ...     0.875207    Naive Bayes\n",
              "F1 Score                 0.795794       0.812828  ...     0.817021  Random Forest\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu1A8E2wvgYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdleKkJ1WAIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC-PR79o2OlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIAKvuxBWAZ5",
        "colab_type": "text"
      },
      "source": [
        "For testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNKdwepNalFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testTrue = list(map(lambda t: t[1], testData))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxBWd0SoczAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy9N9MSsZ1o8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d80ce469-971c-48c5-8785-871b9418825b"
      },
      "source": [
        "svm_classifier = trainClassifier(trainData, svm)\n",
        "svm_testPred = predictLabels(testData, svm_classifier)\n",
        "svm_acc = accuracy_score(testTrue, svm_testPred)\n",
        "print(svm_acc)\n",
        "\n",
        "dt_classifier = trainClassifier(trainData, dt)\n",
        "dt_testPred = predictLabels(testData, dt_classifier)\n",
        "dt_acc = accuracy_score(testTrue, dt_testPred)\n",
        "print(dt_acc)\n",
        "\n",
        "rf_classifier = trainClassifier(trainData, rf)\n",
        "rf_testPred = predictLabels(testData, rf_classifier)\n",
        "rf_acc = accuracy_score(testTrue, rf_testPred)\n",
        "print(rf_acc)\n",
        "\n",
        "nb_classifier = trainClassifier(trainData, nb)\n",
        "nb_testPred = predictLabels(testData, nb_classifier)\n",
        "nb_acc = accuracy_score(testTrue, nb_testPred)\n",
        "print(nb_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Classifier...\n",
            "0.6922115785089547\n",
            "Training Classifier...\n",
            "0.6583090379008746\n",
            "Training Classifier...\n",
            "0.7163681799250312\n",
            "Training Classifier...\n",
            "0.7255310287380258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1vzXr1VEISQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from joblib import dump, load\n",
        "dump(classifier, 'Price_SVC.joblib') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY67JZx9EK_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = load('filename.joblib') "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}