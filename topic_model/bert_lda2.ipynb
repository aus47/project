{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_lda2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "31bcf4b7beef44a28ea7c71fd011037d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5dbdeac32db84ff6afe1bcefa7c97508",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_92591054a31f46dab036087836d6af82",
              "IPY_MODEL_b87be4513b0442df82c17548af31b6a2"
            ]
          }
        },
        "5dbdeac32db84ff6afe1bcefa7c97508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92591054a31f46dab036087836d6af82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_14e65a3231794918a5d7466942caa0d8",
            "_dom_classes": [],
            "description": "Batches: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e3e00a0d519941c39aaf9d5491d79c54"
          }
        },
        "b87be4513b0442df82c17548af31b6a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cba28215572f46ba9e6da91cac8fa531",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2625/2625 [50:01&lt;00:00,  1.14s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ed471cec64744288fdd7dfa785df27e"
          }
        },
        "14e65a3231794918a5d7466942caa0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e3e00a0d519941c39aaf9d5491d79c54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cba28215572f46ba9e6da91cac8fa531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ed471cec64744288fdd7dfa785df27e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqIv85rnRiIV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3921890d-5029-41c3-e955-7b6d8739539a"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.decomposition import NMF"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csXvNOH7gk9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "0d07a8c0-10ad-4e91-ba99-fc5365c30982"
      },
      "source": [
        "data = pd.read_csv('amazon_reviews.txt', sep=\"\\t\",  error_bad_lines=False)\n",
        "x_raw = data['REVIEW_TEXT']\n",
        "x_raw = data['REVIEW_TEXT'].values.tolist()\n",
        "x_raw = [a.replace(\"<br />\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"good\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"great\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"use\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"just\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"really\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"like\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"product\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"the\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"wi\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"one\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"this\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"get\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"is\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"love\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"th\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"wh\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"en\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"se\", \"\") for a in x_raw]\n",
        "x_raw = [a.replace(\"well\", \"\") for a in x_raw]\n",
        "\n",
        "\n",
        "\n",
        "data[['DOC_ID', 'PRODUCT_CATEGORY', 'PRODUCT_TITLE', 'REVIEW_TITLE', 'REVIEW_TEXT']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DOC_ID</th>\n",
              "      <th>PRODUCT_CATEGORY</th>\n",
              "      <th>PRODUCT_TITLE</th>\n",
              "      <th>REVIEW_TITLE</th>\n",
              "      <th>REVIEW_TEXT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>PC</td>\n",
              "      <td>Targus PAUK10U Ultra Mini USB Keypad, Black</td>\n",
              "      <td>useful</td>\n",
              "      <td>When least you think so, this product will sav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Wireless</td>\n",
              "      <td>Note 3 Battery : Stalion Strength Replacement ...</td>\n",
              "      <td>New era for batteries</td>\n",
              "      <td>Lithium batteries are something new introduced...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Baby</td>\n",
              "      <td>Fisher-Price Papasan Cradle Swing, Starlight</td>\n",
              "      <td>doesn't swing very well.</td>\n",
              "      <td>I purchased this swing for my baby. She is 6 m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Office Products</td>\n",
              "      <td>Casio MS-80B Standard Function Desktop Calculator</td>\n",
              "      <td>Great computing!</td>\n",
              "      <td>I was looking for an inexpensive desk calcolat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>Shine Whitening - Zero Peroxide Teeth Whitenin...</td>\n",
              "      <td>Only use twice a week</td>\n",
              "      <td>I only use it twice a week and the results are...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   DOC_ID  ...                                        REVIEW_TEXT\n",
              "0       1  ...  When least you think so, this product will sav...\n",
              "1       2  ...  Lithium batteries are something new introduced...\n",
              "2       3  ...  I purchased this swing for my baby. She is 6 m...\n",
              "3       4  ...  I was looking for an inexpensive desk calcolat...\n",
              "4       5  ...  I only use it twice a week and the results are...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9X7yBVCSHUO"
      },
      "source": [
        "#Preprocess corpus\n",
        "import string\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def preprocess(text):\n",
        "    # word tokenisation, including punctuation removal\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "    #text = [t for t in text if t not in stop]\n",
        "    for sent in text:\n",
        "        yield(gensim.utils.simple_preprocess(str(sent)))\n",
        "\n",
        "\n",
        "    # lowercasing\n",
        "    text = [t.lower() for t in text]\n",
        "\n",
        "       # stopword removal\n",
        "    #stop = set(stopwords.words('english'))\n",
        "    #text = str([[word for word in sent if word not in stop] for sent in text])\n",
        "    \n",
        "    # lemmatisation\n",
        "    lemmatiser = WordNetLemmatizer()\n",
        "    text = [lemmatiser.lemmatize(t) for t in text]\n",
        "    # remove numbers and empty space\n",
        "    digits = ' 0123456789'\n",
        "    text = [t for t in text if t not in digits]\n",
        "\n",
        "    #stop = set(stopwords.words('english'))\n",
        "    #text = [t for t in text if t not in stop]\n",
        "\n",
        "    #tokenize sentences\n",
        "\n",
        "\n",
        "        \n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSSy6vj9SRkE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "edeb2605-9e36-4119-fc61-3a018dd9b203"
      },
      "source": [
        "x = list(preprocess(x_raw))\n",
        "#x = str(preprocess(x_raw))\n",
        "#x = list(x)\n",
        "\n",
        "bigram = gensim.models.Phrases(x, min_count=3, threshold=40)\n",
        "x = [bigram[line] for line in x]\n",
        "x_train = [' '.join(i) for i in x]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpTJ7VcoDMFL"
      },
      "source": [
        "stop = set(stopwords.words('english'))\n",
        "x = [[t for t in sent if t not in stop] for sent in x]\n",
        "\n",
        "x = [[a.replace(\"th\", \"\") for a in sent] for sent in x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90H1DX0_DmpJ"
      },
      "source": [
        "x_train = [' '.join(i) for i in x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1LK02fsOOzb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7da86395-cb0e-4d37-aebf-6487e23ae355"
      },
      "source": [
        "print(x[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['wh', 'least', 'ink', 'save', 'day', 'keep', 'around', 'ca', 'need', 'someing'], ['liium_batteries', 'someing', 'new', 'introduced', 'market', 'average', 'developing', 'cost', 'relatively', 'high', 'stallion', 'comprome', 'quality', 'provides', 'us', 'best', 'low_cost', 'many', 'built', 'technical', 'asstants', 'act', 'ssor', 'ir', 'particular', 'fortÃ©', 'battery', 'keeps', 'ph', 'charged', 'works', 'every', 'voltage', 'high', 'voltage', 'never', 'rked'], ['purchad', 'sng', 'baby', 'mons', 'pretty', 'much', 'grown', 'loud', 'sng', 'well', 'beautiful', 'ough', 'colors', 'lot', 'ttings', 'ink', 'wor'], ['looking', 'inexpsive', 'desk', 'calcolatur', 'works', 'everying', 'need', 'sue', 'tilts', 'slightly', 'side', 'hit', 'keys', 'rocks', 'little', 'bit', 'big_deal'], ['tce_week', 'results', 'tee', 'iting', 'solutions', 'results', 'would', 'least', 'ree_times', 'week', 'keep', 'using', 'beca', 'potcy', 'solution', 'also', 'technique', 'trays', 'keeps', 'everying', 'tee', 'mou'], ['sure', 'suppod', 'would', 'recommd', 'little', 'rearch', 'culture', 'using', 'pipes', 'plan', 'giving', 'gift', 'using', 'yourlf'], ['plead', 'ping_pong', 'table', 'year_old', 'year_old', 'having_blast', 'plus', 'lots', 'family', 'tertainmt', 'plus', 'better', 'kids', 'sitting', 'video', 'games', 'day', 'frid', 'put', 'toger', 'believe', 'challge', 'noing', 'could', 'handle'], ['great', 'vitamin_rum', 'oil', 'feeling', 'sticky', 'last', 'week', 'rect', 'bug', 'bites', 'helps', 'heal', 'skin', 'faster', 'normal'], ['tide', 'pods', 'laundry', 'detergt', 'many', 'years', 'detergt', 'nice', 'sct', 'leaver', 'clos', 'smelling_fresh'], ['everybody', 'wants', 'fall', 'ir', 'promes', 'relatively', 'unheard', 'brand', 'ev', 'say', 'non', 'extant', 'company', 'look', 'amateur', 'ir', 'labels', 'ask', 'yourlf', 'would', 'trust', 'kind', 'amateur', 'stuff', 'way', 'don_waste'], ['unfortunately', 'work', 'made', 'sick', 'row', 'two', 'times', 'tried'], ['', 'kettle', 'gift', 'daughter', 'said', 'easy', 'design', 'nice', 'neat'], ['tumbler', 'keeps', 'drinks', 'warm', 'cold', 'period', 'time', 'sturdy', 'complemts', 'sleek', 'looks', 'time', 'especially', 'beca', 'doesnt', 'leave', 'fingerprints', 'highly_recommd', 'suggestion', 'washing', 'lid', 'sure', 'shake', 'dry', 'well', 'prevt', 'dripping', 'lid', 'tumbler'], ['giving_stars', 'beca', 'cheap', 'mild', 'dative', 'effect', 'pretty', 'less', 'stress', 'anxiety', 'panic_attacks', 'save', 'ad', 'zrx', 'night', 'day', 'differce', 'asin', 'hbgbry', 'zrx', 'dietary_supplemt', 'reduces_symptoms', 'anxiety_stress', 'depression', 'panic_attacks', 'boost', 'mood', 'increa', 'relaxation', 'beat', 'anxiety_kava', 'kava_htp', 'eanine_gaba', 'back_guarantee'], ['bought', 'brown', 'land', 'hydraulic', 'mechanm', 'looks', 'ough', 'might', 'fail', 'color', 'accurate', 'description', 'padding', 'much', 'definitely', 'chair', 'would', 'lounge', 'around', 'bar', 'counter', 'kitch'], ['wonderful', 'headphs', 'mons', 'works', 'also', 'price', 'sound', 'clear', 'loud', 'soft', 'ears', 'headphs', 'mtion', 'sony'], ['video', 'quality', 'superb', 'fits', 'fine', 'looks', 'real', 'mirror', 'believe', 'hanced', 'only_gripe', 'sh', 'put', 'cameras', 'side', 'side', 'side', 'side', 'say', 'beca', 'due', 'ere', 'left', 'camera', 'place', 'wasted', 'recording', 'room', 'start', 'turn', 'towards', 'driver', 'side', 'happy', 'far'], ['sling', 'shots', 'go', 'ough', 'purpos', 'ough', 'would', 'preferred', 'handle', 'slimmer', 'better', 'grip'], ['fair', 'believe', 'slicer', 'idea', 'unfortunately', 'tricks', 'using', 'spiral', 'slicer', 'mean', 'manual', 'someing', 'would', 'helpful', 'saying', 'someing', 'negative', 'slicer', 'beca', 'work', 'however', 'took', 'almost', 'week', 'trying', 'learn', 'slicer', 'cutting', 'differt', 'kinds', 'veable', 'price', 'may', 'say', 'fair', 'sh', 'manuals', 'every', 'box', 'shong', 'us', 'slicer', 'properly'], ['tablets', 'especially', 'helpful', 'secure', 'dtal', 'adhesive', 'bought', 'stuff', 'far', 'satfied']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOvWneCrSTF4"
      },
      "source": [
        "from gensim import corpora\n",
        "dictionary = corpora.Dictionary(x)\n",
        "corpus = [dictionary.doc2bow(text) for text in x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBRcQ5r9XF6w"
      },
      "source": [
        "from lda2vec import LDA2Vec\n",
        "#from lda2vec import dirichlet_likelihood\n",
        "#from lda2vec import *\n",
        "import pyLDAvis\n",
        "\n",
        "model = LDA2Vec(n_words, max_length, n_hidden, counts)\n",
        "model.add_component(n_docs, n_topics, name='document id')\n",
        "model.fit(clean, components=[doc_ids])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y27LCGwHTLV_"
      },
      "source": [
        "lda_model = gensim.models.ldamodel.LdaModel(corpus, num_topics=10, id2word=dictionary, passes=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2sk5FAotwgA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "444e0d89-4fba-4ec9-8545-c8db8ff8b991"
      },
      "source": [
        "def get_vec_lda(model, corpus, k):\n",
        "    n_doc = len(corpus)\n",
        "    vec_lda = np.zeros((n_doc, k))\n",
        "    for i in range(n_doc):\n",
        "                    # get the distribution for the i-th document in corpus\n",
        "          for topic, prob in model.get_document_topics(corpus[i]):\n",
        "              vec_lda[i, topic] = prob\n",
        "\n",
        "    return vec_lda\n",
        "\n",
        "veclda = get_vec_lda(lda_model, corpus, 10)\n",
        "print('Getting vector representations for LDA. Done!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting vector representations for LDA. Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmj_HHV1T_6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "31bcf4b7beef44a28ea7c71fd011037d",
            "5dbdeac32db84ff6afe1bcefa7c97508",
            "92591054a31f46dab036087836d6af82",
            "b87be4513b0442df82c17548af31b6a2",
            "14e65a3231794918a5d7466942caa0d8",
            "e3e00a0d519941c39aaf9d5491d79c54",
            "cba28215572f46ba9e6da91cac8fa531",
            "0ed471cec64744288fdd7dfa785df27e"
          ]
        },
        "outputId": "2249214c-bfd3-42f0-fa86-8f1750a53064"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "bert_model = SentenceTransformer('bert-base-nli-max-tokens')\n",
        "vec = np.array(bert_model.encode(x_train, show_progress_bar=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31bcf4b7beef44a28ea7c71fd011037d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Batches', max=2625.0, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmgAyD4ggvnS"
      },
      "source": [
        "lda_bert = np.c_[veclda * 15, vec]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEAreLQIVoDp"
      },
      "source": [
        "import keras\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class Autoencoder:\n",
        "    \"\"\"\n",
        "    Autoencoder for learning latent space representation\n",
        "    architecture simplified for only one hidden layer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, latent_dim=32, activation='relu', epochs=200, batch_size=128):\n",
        "        self.latent_dim = latent_dim\n",
        "        self.activation = activation\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.autoencoder = None\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "        self.his = None\n",
        "\n",
        "    def _compile(self, input_dim):\n",
        "        \"\"\"\n",
        "        compile the computational graph\n",
        "        \"\"\"\n",
        "        input_vec = Input(shape=(input_dim,))\n",
        "        encoded = Dense(self.latent_dim, activation=self.activation)(input_vec)\n",
        "        decoded = Dense(input_dim, activation=self.activation)(encoded)\n",
        "        self.autoencoder = Model(input_vec, decoded)\n",
        "        self.encoder = Model(input_vec, encoded)\n",
        "        encoded_input = Input(shape=(self.latent_dim,))\n",
        "        decoder_layer = self.autoencoder.layers[-1]\n",
        "        self.decoder = Model(encoded_input, self.autoencoder.layers[-1](encoded_input))\n",
        "        self.autoencoder.compile(optimizer='adam', loss=keras.losses.mean_squared_error)\n",
        "\n",
        "    def fit(self, X):\n",
        "        if not self.autoencoder:\n",
        "            self._compile(X.shape[1])\n",
        "        X_train, X_test = train_test_split(X)\n",
        "        self.his = self.autoencoder.fit(X_train, X_train,\n",
        "                                        epochs=200,\n",
        "                                        batch_size=128,\n",
        "                                        shuffle=True,\n",
        "                                        validation_data=(X_test, X_test), verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-InEsgruf0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3b42b6-2d93-4d8f-b38a-c5006e0c8579"
      },
      "source": [
        "AE = Autoencoder()\n",
        "print('Fitting Autoencoder ...')\n",
        "AE.fit(lda_bert)\n",
        "print('Fitting Autoencoder Done!')\n",
        "vec = AE.encoder.predict(lda_bert)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting Autoencoder ...\n",
            "Fitting Autoencoder Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtPhhftR1bEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2295d5d-fc2c-469d-f3f9-b0273986d061"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "m_clustering = KMeans\n",
        "cluster_model = m_clustering(10)\n",
        "#final_vec = vectorize(x_train, x)\n",
        "cluster_model.fit(vec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=10, n_init=10, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=None, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxWMSeQuwoOb"
      },
      "source": [
        "def get_topic_words(token_lists, labels, k=None):\n",
        "    \"\"\"\n",
        "    get top words within each topic from clustering results\n",
        "    \"\"\"\n",
        "    if k is None:\n",
        "        k = len(np.unique(labels))\n",
        "    topics = ['' for _ in range(k)]\n",
        "    for i, c in enumerate(token_lists):\n",
        "        topics[labels[i]] += (' ' + ' '.join(c))\n",
        "    word_counts = list(map(lambda x: Counter(x.split()).items(), topics))\n",
        "    # get sorted word counts\n",
        "    word_counts = list(map(lambda x: sorted(x, key=lambda x: x[1], reverse=True), word_counts))\n",
        "    # get topics\n",
        "    topics = list(map(lambda x: list(map(lambda x: x[0], x[:10])), word_counts))\n",
        "\n",
        "    return topics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH_cFVSHxYe5"
      },
      "source": [
        "topics = get_topic_words(x, cluster_model.labels_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn7tFgx3nl76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5659716-0e32-47f0-c236-61966e687a51"
      },
      "source": [
        "df_topic_keywords = pd.DataFrame(topics)\n",
        "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
        "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
        "display(df_topic_keywords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word 0</th>\n",
              "      <th>Word 1</th>\n",
              "      <th>Word 2</th>\n",
              "      <th>Word 3</th>\n",
              "      <th>Word 4</th>\n",
              "      <th>Word 5</th>\n",
              "      <th>Word 6</th>\n",
              "      <th>Word 7</th>\n",
              "      <th>Word 8</th>\n",
              "      <th>Word 9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Topic 0</th>\n",
              "      <td>coffee</td>\n",
              "      <td>also</td>\n",
              "      <td>taste</td>\n",
              "      <td>tea</td>\n",
              "      <td>make</td>\n",
              "      <td>water</td>\n",
              "      <td>easy</td>\n",
              "      <td>would</td>\n",
              "      <td>much</td>\n",
              "      <td>ich</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 1</th>\n",
              "      <td>tv</td>\n",
              "      <td>watch</td>\n",
              "      <td>quality</td>\n",
              "      <td>works</td>\n",
              "      <td>easy</td>\n",
              "      <td>price</td>\n",
              "      <td>time</td>\n",
              "      <td>would</td>\n",
              "      <td>light</td>\n",
              "      <td>sound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 2</th>\n",
              "      <td>bag</td>\n",
              "      <td>easy</td>\n",
              "      <td>small</td>\n",
              "      <td>would</td>\n",
              "      <td>also</td>\n",
              "      <td>nice</td>\n",
              "      <td>ough</td>\n",
              "      <td>fit</td>\n",
              "      <td>size</td>\n",
              "      <td>little</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 3</th>\n",
              "      <td>book</td>\n",
              "      <td>read</td>\n",
              "      <td>time</td>\n",
              "      <td>would</td>\n",
              "      <td>also</td>\n",
              "      <td>much</td>\n",
              "      <td>many</td>\n",
              "      <td>ev</td>\n",
              "      <td>first</td>\n",
              "      <td>ir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 4</th>\n",
              "      <td>dog</td>\n",
              "      <td>would</td>\n",
              "      <td>time</td>\n",
              "      <td>bought</td>\n",
              "      <td>much</td>\n",
              "      <td>buy</td>\n",
              "      <td>beca</td>\n",
              "      <td>also</td>\n",
              "      <td>using</td>\n",
              "      <td>ich</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 5</th>\n",
              "      <td>quality</td>\n",
              "      <td>nice</td>\n",
              "      <td>perfect</td>\n",
              "      <td>price</td>\n",
              "      <td>would</td>\n",
              "      <td>looks</td>\n",
              "      <td>easy</td>\n",
              "      <td>happy</td>\n",
              "      <td>fit</td>\n",
              "      <td>color</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 6</th>\n",
              "      <td>price</td>\n",
              "      <td>would</td>\n",
              "      <td>quality</td>\n",
              "      <td>buy</td>\n",
              "      <td>bought</td>\n",
              "      <td>little</td>\n",
              "      <td>cheap</td>\n",
              "      <td>size</td>\n",
              "      <td>recommd</td>\n",
              "      <td>much</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 7</th>\n",
              "      <td>game</td>\n",
              "      <td>movie</td>\n",
              "      <td>time</td>\n",
              "      <td>ir</td>\n",
              "      <td>play</td>\n",
              "      <td>would</td>\n",
              "      <td>ich</td>\n",
              "      <td>also</td>\n",
              "      <td>story</td>\n",
              "      <td>film</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 8</th>\n",
              "      <td>time</td>\n",
              "      <td>would</td>\n",
              "      <td>got</td>\n",
              "      <td>work</td>\n",
              "      <td>bought</td>\n",
              "      <td>beca</td>\n",
              "      <td>little</td>\n",
              "      <td>first</td>\n",
              "      <td>ev</td>\n",
              "      <td>using</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 9</th>\n",
              "      <td>would</td>\n",
              "      <td>time</td>\n",
              "      <td>beca</td>\n",
              "      <td>also</td>\n",
              "      <td>little</td>\n",
              "      <td>ich</td>\n",
              "      <td>much</td>\n",
              "      <td>ev</td>\n",
              "      <td>ough</td>\n",
              "      <td>first</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Word 0 Word 1   Word 2  Word 3  ...  Word 6 Word 7   Word 8  Word 9\n",
              "Topic 0   coffee   also    taste     tea  ...    easy  would     much     ich\n",
              "Topic 1       tv  watch  quality   works  ...    time  would    light   sound\n",
              "Topic 2      bag   easy    small   would  ...    ough    fit     size  little\n",
              "Topic 3     book   read     time   would  ...    many     ev    first      ir\n",
              "Topic 4      dog  would     time  bought  ...    beca   also    using     ich\n",
              "Topic 5  quality   nice  perfect   price  ...    easy  happy      fit   color\n",
              "Topic 6    price  would  quality     buy  ...   cheap   size  recommd    much\n",
              "Topic 7     game  movie     time      ir  ...     ich   also    story    film\n",
              "Topic 8     time  would      got    work  ...  little  first       ev   using\n",
              "Topic 9    would   time     beca    also  ...    much     ev     ough   first\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb2d_w_7uP1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ec171fc-1f5c-42e6-e1dd-f7292593b4ee"
      },
      "source": [
        "!pip install lda2vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lda2vec in /usr/local/lib/python3.6/dist-packages (0.16.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y7jKUXZXS3K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "bba52225-bdce-4fca-ef19-812ef711a769"
      },
      "source": [
        "!pip show lda2vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: lda2vec\n",
            "Version: 0.16.10\n",
            "Summary: Tools for interpreting natural language\n",
            "Home-page: UNKNOWN\n",
            "Author: Nathan Raw\n",
            "Author-email: nxr9266@rit.edu\n",
            "License: UNKNOWN\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: \n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOtwevYlbHS3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "95d03bad-550c-4d67-af35-14325676250c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw4mlr5Haoy0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}